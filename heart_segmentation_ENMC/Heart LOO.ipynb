{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Heart LOO.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1P9E6v0xx8yYmOoZdGlsUGI6izyZAguwq","authorship_tag":"ABX9TyO/QgjeroHVIvQmuUBoGBRa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Q7VQ2tvdN_o","executionInfo":{"status":"ok","timestamp":1636642619607,"user_tz":180,"elapsed":467,"user":{"displayName":"Mauro Testes","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15754463744347175259"}},"outputId":"084969c6-8cf3-4819-9700-1227aceb61e9"},"source":["%cd ./drive/MyDrive/heart_segmentation_ENMC/"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/heart_segmentation_ENMC\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CcbXgEXod3Bb","executionInfo":{"status":"ok","timestamp":1636642622071,"user_tz":180,"elapsed":447,"user":{"displayName":"Mauro Testes","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15754463744347175259"}},"outputId":"af06c4f1-b9a0-410a-e7cf-a2075be6cf00"},"source":["%tensorflow_version 1.x"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow 1.x selected.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CGiPkwvndSzY","executionInfo":{"status":"ok","timestamp":1636642687367,"user_tz":180,"elapsed":63472,"user":{"displayName":"Mauro Testes","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15754463744347175259"}},"outputId":"0ff94526-9871-41c3-93d3-e4400cf8460d"},"source":["from unet import unet_reduzida, unet_completa, unet_n, dice_coef\n","from utils import get_images, separate_train_test, make_vol, image_preprocess\n","import glob\n","from keras import backend as K\n","import numpy as np\n","import tensorflow as tf\n","from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from time import time\n","\n","hd = [45 , 25, 40 , 40 , 13, 40, 42 , 33, 6 , 43 , 37 , 8 , 28, 18, 46 , 37, 41 , 41 , 33, 33 ]\n","hu = [112, 95, 113, 116, 91, 98, 109, 98, 67, 105, 104, 81, 97, 88, 103, 90, 110, 113, 92, 101]\n","\n","x_train = sorted(glob.glob('data_heart/imagesTr/*'))\n","y_train = sorted(glob.glob('data_heart/labelsTr/*'))\n","img_xtrain, index_x = get_images(x_train,hd,hu)\n","img_ytrain, index_y = get_images(y_train,hd,hu)\n","\n","#predict_vol = []\n","dice_metric = []\n","tempo = []\n","local = 'heart_tests/heart_LOO_ES/'\n"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Using TensorFlow backend.\n"]}]},{"cell_type":"code","metadata":{"id":"n_0t7hy-hxjD"},"source":["# nº 2 DataAug\n","\n","\n","data_gen_args = dict(shear_range=0.2,\n","                    zoom_range=0.2,\n","                    horizontal_flip=True)\n","\n","image_datagen = ImageDataGenerator(**data_gen_args)\n","\n","\n","image_generator = image_datagen.flow(train_X, train_ground,\n","        batch_size=use_batch_size,\n","        seed=SEED_2)\n","\n","epoch = 100\n","spe = 300\n","\n","history = model.fit_generator(image_generator, steps_per_epoch=spe, epochs=epoch, callbacks=callback)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SyCGYqgyhx0b"},"source":["# nº 3 FMédias\n","\n","def mean_filter(image, filter_size):\n","    new_image = cv2.blur(image,(filter_size, filter_size))\n","    return new_image\n","def apply_mean_filter():\n","    filter_size = 9 \n","    imgs_list = []\n","    for img in imgs_load:\n","        imgs_list.append(mean_filter(img, filter_size))\n","    return imgs_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PUrHT_HnjN6D"},"source":["train_X.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qymw3UMMdZZM"},"source":["for i in range(len(img_xtrain)):\n","    \n","    print(\"Rodando Pela %i vez\"%(i+1))\n","    \n","    train_X, valid_X, index_train_x, index_test_x = separate_train_test(img_xtrain, index = i)\n","    train_ground, valid_ground, index_train_y, index_test_y = separate_train_test(img_ytrain, index = i)\n","    \n","    size_img = 128\n","    \n","    train_X, valid_X, train_ground, valid_ground = image_preprocess(train_X, valid_X, train_ground, valid_ground)\n","    \n","    inicial = time()\n","    model = unet_n(size_img, mult = 2)\n","    \n","    reduce = ReduceLROnPlateau(monitor = 'loss', patience = 2, verbose = 1)\n","    es = EarlyStopping(monitor = 'loss', patience = 5, verbose = 1)\n","    \n","    history = model.fit(x = train_X, y = train_ground, batch_size = 4, epochs = 100, callbacks = [reduce, es])\n","    final = time()\n","    \n","    model.save(local + 'Heart_Model_%i.h5'%(i))\n","        \n","    predicao = model.predict(valid_X)\n","    #predict_vol.append(make_vol(predicao, index = index_test_y))\n","    predicao = predicao > 0.5\n","    predicao = np.float64(predicao)\n","\n","    sess = tf.InteractiveSession()\n","    dice_metric.append(dice_coef(predicao, valid_ground).eval())\n","    sess.close()\n","\n","    tempo_total = final - inicial\n","    tempo.append(tempo_total)\n","    print(\"rodou em : %f\"%(tempo_total))\n","    K.clear_session()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q0pfV3_ddd-n"},"source":["np.savetxt(local + 'Dice Metric.txt', dice_metric)\n","np.savetxt(local + 'Tempo.txt', tempo)"],"execution_count":null,"outputs":[]}]}